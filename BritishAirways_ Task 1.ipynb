{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaa8a44",
   "metadata": {},
   "source": [
    "# Task_1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a6ca0",
   "metadata": {},
   "source": [
    "#### Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called BeautifulSoup to collect the data from the web. Once you've collected your data and saved it into a local .csv file you should start with your analysis.\n",
    "\n",
    "#### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "#### If you navigate to this link:\n",
    "\n",
    "[https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use Python and BeautifulSoup to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941e47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e43f5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1992d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified | Regarding the aircraft and seat...\n",
       "1  Not Verified | I travelled with British Airway...\n",
       "2  Not Verified |  Food was lousy. Who ever is pl...\n",
       "3  ✅ Trip Verified | Had the worst experience. Th...\n",
       "4  ✅ Trip Verified |  The ground staff were not h..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936349b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>✅ Trip Verified |  Mumbai to Edinburgh via Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>✅ Trip Verified |  Mumbai to London Heathrow. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>✅ Trip Verified |  Delhi to London. Having rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>✅ Trip Verified | When you travel British Airw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>✅ Trip Verified |  British Airways gets plenty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    Not Verified | Regarding the aircraft and seat...\n",
       "1    Not Verified | I travelled with British Airway...\n",
       "2    Not Verified |  Food was lousy. Who ever is pl...\n",
       "3    ✅ Trip Verified | Had the worst experience. Th...\n",
       "4    ✅ Trip Verified |  The ground staff were not h...\n",
       "..                                                 ...\n",
       "995  ✅ Trip Verified |  Mumbai to Edinburgh via Lon...\n",
       "996  ✅ Trip Verified |  Mumbai to London Heathrow. ...\n",
       "997  ✅ Trip Verified |  Delhi to London. Having rea...\n",
       "998  ✅ Trip Verified | When you travel British Airw...\n",
       "999  ✅ Trip Verified |  British Airways gets plenty...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55a673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviews= df.reviews.str.split('|',expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e34dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Mumbai to Edinburgh via London. I'm quite su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Mumbai to London Heathrow. Disappointing exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Delhi to London. Having read many negative r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>When you travel British Airways its like you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>British Airways gets plenty of well deserved...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0     Regarding the aircraft and seat: The business...\n",
       "1     I travelled with British Airways from Sweden ...\n",
       "2      Food was lousy. Who ever is planning the Asi...\n",
       "3     Had the worst experience. The flight from Lon...\n",
       "4      The ground staff were not helpful. Felt like...\n",
       "..                                                 ...\n",
       "995    Mumbai to Edinburgh via London. I'm quite su...\n",
       "996    Mumbai to London Heathrow. Disappointing exp...\n",
       "997    Delhi to London. Having read many negative r...\n",
       "998   When you travel British Airways its like you ...\n",
       "999    British Airways gets plenty of well deserved...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909abbd",
   "metadata": {},
   "source": [
    "Rule-based approach\n",
    "\n",
    "- This is a practical approach to analyzing text without training or using machine learning models. The result of this approach is a set of rules based on which the text is labeled as positive/negative/neutral. These rules are also known as lexicons. Hence, the Rule-based approach is called Lexicon based approach.\n",
    "\n",
    "- Widely used lexicon-based approaches are TextBlob, VADER, SentiWordNet.\n",
    "\n",
    "Data preprocessing steps:\n",
    "\n",
    "- Cleaning the text\n",
    "\n",
    "- Tokenization\n",
    "\n",
    "- Enrichment – POS tagging\n",
    "\n",
    "- Stopwords removal\n",
    "\n",
    "- Obtaining the stem words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd67608",
   "metadata": {},
   "source": [
    "### Data Cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaea8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "      <td>Regarding the aircraft and seat The business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "      <td>Food was lousy Who ever is planning the Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "      <td>Had the worst experience The flight from Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>The ground staff were not helpful Felt like a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0   Regarding the aircraft and seat: The business...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2    Food was lousy. Who ever is planning the Asi...   \n",
       "3   Had the worst experience. The flight from Lon...   \n",
       "4    The ground staff were not helpful. Felt like...   \n",
       "\n",
       "                                     Cleaned Reviews  \n",
       "0   Regarding the aircraft and seat The business ...  \n",
       "1   I travelled with British Airways from Sweden ...  \n",
       "2   Food was lousy Who ever is planning the Asian...  \n",
       "3   Had the worst experience The flight from Lond...  \n",
       "4   The ground staff were not helpful Felt like a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "# Cleaning the text in the review column\n",
    "df['Cleaned Reviews'] = df['reviews'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac17962",
   "metadata": {},
   "source": [
    "### Tokenization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe7f02",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking the text into smaller pieces called Tokens. It can be performed at sentences(sentence tokenization) or word level(word tokenization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45478911",
   "metadata": {},
   "source": [
    "### Enrichment – POS tagging:\n",
    "\n",
    "\n",
    "Parts of Speech (POS) tagging is a process of converting each token into a tuple having the form (word, tag). POS tagging essential to preserve the context of the word and is essential for Lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e664d",
   "metadata": {},
   "source": [
    "### Stopwords removal:\n",
    "\n",
    "Stopwords in English are words that carry very little useful information. We need to remove them as part of text preprocessing. nltk has a list of stopwords of every language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7882c0",
   "metadata": {},
   "source": [
    "### Obtaining the stem words\n",
    "A stem is a part of a word responsible for its lexical meaning. The two popular techniques of obtaining the root/stem words are Stemming and Lemmatization.\n",
    "\n",
    "The key difference is Stemming often gives some meaningless root words as it simply chops off some characters in the end. Lemmatization gives meaningful root words, however, it requires POS tags of the words.\n",
    "\n",
    "- NLTK is a leading platform for building Python programs to work with human language data. \n",
    "\n",
    "- It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along \n",
    "  with a suite of text processing libraries for classification, tokenization, stemming, tagging, \n",
    "  parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f892c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\"\"\"This punkt tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, \n",
    "collocations, and words that start sentences. \"\"\"\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102adfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "      <td>Regarding the aircraft and seat The business ...</td>\n",
       "      <td>[(Regarding, v), (aircraft, n), (seat, v), (bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>[(travelled, v), (British, a), (Airways, n), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "      <td>Food was lousy Who ever is planning the Asian...</td>\n",
       "      <td>[(Food, n), (lousy, n), (ever, r), (planning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "      <td>Had the worst experience The flight from Lond...</td>\n",
       "      <td>[(worst, a), (experience, n), (flight, n), (Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>The ground staff were not helpful Felt like a...</td>\n",
       "      <td>[(ground, n), (staff, n), (helpful, a), (Felt,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0   Regarding the aircraft and seat: The business...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2    Food was lousy. Who ever is planning the Asi...   \n",
       "3   Had the worst experience. The flight from Lon...   \n",
       "4    The ground staff were not helpful. Felt like...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0   Regarding the aircraft and seat The business ...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2   Food was lousy Who ever is planning the Asian...   \n",
       "3   Had the worst experience The flight from Lond...   \n",
       "4   The ground staff were not helpful Felt like a...   \n",
       "\n",
       "                                          POS tagged  \n",
       "0  [(Regarding, v), (aircraft, n), (seat, v), (bu...  \n",
       "1  [(travelled, v), (British, a), (Airways, n), (...  \n",
       "2  [(Food, n), (lousy, n), (ever, r), (planning, ...  \n",
       "3  [(worst, a), (experience, n), (flight, n), (Lo...  \n",
       "4  [(ground, n), (staff, n), (helpful, a), (Felt,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The nltk.corpus package defines a collection of corpus reader classes, which can be used to access the contents of a diverse set of corpora.\n",
    "\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    #print(tags)\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "          newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "          #print(tag[0])\n",
    "          #print(pos_dict.get(tag[0]))\n",
    "    return newlist \n",
    "\n",
    "df['POS tagged'] = df['Cleaned Reviews'].apply(token_stop_pos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3849be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "      <td>Regarding the aircraft and seat The business ...</td>\n",
       "      <td>[(Regarding, v), (aircraft, n), (seat, v), (bu...</td>\n",
       "      <td>Regarding aircraft seat business class seat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>[(travelled, v), (British, a), (Airways, n), (...</td>\n",
       "      <td>travel British Airways Sweden Los Angeles vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "      <td>Food was lousy Who ever is planning the Asian...</td>\n",
       "      <td>[(Food, n), (lousy, n), (ever, r), (planning, ...</td>\n",
       "      <td>Food lousy ever plan Asian Hindu Vegetarian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "      <td>Had the worst experience The flight from Lond...</td>\n",
       "      <td>[(worst, a), (experience, n), (flight, n), (Lo...</td>\n",
       "      <td>bad experience flight London Toronto get del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>The ground staff were not helpful Felt like a...</td>\n",
       "      <td>[(ground, n), (staff, n), (helpful, a), (Felt,...</td>\n",
       "      <td>ground staff helpful Felt like want rush us ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0   Regarding the aircraft and seat: The business...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2    Food was lousy. Who ever is planning the Asi...   \n",
       "3   Had the worst experience. The flight from Lon...   \n",
       "4    The ground staff were not helpful. Felt like...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0   Regarding the aircraft and seat The business ...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2   Food was lousy Who ever is planning the Asian...   \n",
       "3   Had the worst experience The flight from Lond...   \n",
       "4   The ground staff were not helpful Felt like a...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(Regarding, v), (aircraft, n), (seat, v), (bu...   \n",
       "1  [(travelled, v), (British, a), (Airways, n), (...   \n",
       "2  [(Food, n), (lousy, n), (ever, r), (planning, ...   \n",
       "3  [(worst, a), (experience, n), (flight, n), (Lo...   \n",
       "4  [(ground, n), (staff, n), (helpful, a), (Felt,...   \n",
       "\n",
       "                                               Lemma  \n",
       "0    Regarding aircraft seat business class seat ...  \n",
       "1    travel British Airways Sweden Los Angeles vi...  \n",
       "2    Food lousy ever plan Asian Hindu Vegetarian ...  \n",
       "3    bad experience flight London Toronto get del...  \n",
       "4    ground staff helpful Felt like want rush us ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining the stem words – Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "     if not pos:\n",
    "        lemma = word\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "     else:\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "        lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "df['Lemma'] = df['POS tagged'].apply(lemmatize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f0c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "      <td>Regarding aircraft seat business class seat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>travel British Airways Sweden Los Angeles vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "      <td>Food lousy ever plan Asian Hindu Vegetarian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "      <td>bad experience flight London Toronto get del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>ground staff helpful Felt like want rush us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Mumbai to Edinburgh via London. I'm quite su...</td>\n",
       "      <td>Mumbai Edinburgh via London quite surprised ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Mumbai to London Heathrow. Disappointing exp...</td>\n",
       "      <td>Mumbai London Heathrow Disappointing experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Delhi to London. Having read many negative r...</td>\n",
       "      <td>Delhi London read many negative review Briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>When you travel British Airways its like you ...</td>\n",
       "      <td>travel British Airways like lucky able Briti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>British Airways gets plenty of well deserved...</td>\n",
       "      <td>British Airways get plenty well deserve kick...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "0     Regarding the aircraft and seat: The business...   \n",
       "1     I travelled with British Airways from Sweden ...   \n",
       "2      Food was lousy. Who ever is planning the Asi...   \n",
       "3     Had the worst experience. The flight from Lon...   \n",
       "4      The ground staff were not helpful. Felt like...   \n",
       "..                                                 ...   \n",
       "995    Mumbai to Edinburgh via London. I'm quite su...   \n",
       "996    Mumbai to London Heathrow. Disappointing exp...   \n",
       "997    Delhi to London. Having read many negative r...   \n",
       "998   When you travel British Airways its like you ...   \n",
       "999    British Airways gets plenty of well deserved...   \n",
       "\n",
       "                                                 Lemma  \n",
       "0      Regarding aircraft seat business class seat ...  \n",
       "1      travel British Airways Sweden Los Angeles vi...  \n",
       "2      Food lousy ever plan Asian Hindu Vegetarian ...  \n",
       "3      bad experience flight London Toronto get del...  \n",
       "4      ground staff helpful Felt like want rush us ...  \n",
       "..                                                 ...  \n",
       "995    Mumbai Edinburgh via London quite surprised ...  \n",
       "996    Mumbai London Heathrow Disappointing experie...  \n",
       "997    Delhi London read many negative review Briti...  \n",
       "998    travel British Airways like lucky able Briti...  \n",
       "999    British Airways get plenty well deserve kick...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['reviews','Lemma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed0a05",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using VADER\n",
    "\n",
    "\n",
    "VADER stands for Valence Aware Dictionary and Sentiment Reasoner.\n",
    "\n",
    "- Vader sentiment not only tells if the statement is positive or negative along with the intensity of emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b5bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in e:\\applications\\anaconda\\lib\\site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\applications\\anaconda\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\applications\\anaconda\\lib\\site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\applications\\anaconda\\lib\\site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\applications\\anaconda\\lib\\site-packages (from requests->vaderSentiment) (3.3)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e8d091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Cleaned Reviews</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regarding the aircraft and seat: The business...</td>\n",
       "      <td>Regarding the aircraft and seat The business ...</td>\n",
       "      <td>[(Regarding, v), (aircraft, n), (seat, v), (bu...</td>\n",
       "      <td>Regarding aircraft seat business class seat ...</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "      <td>[(travelled, v), (British, a), (Airways, n), (...</td>\n",
       "      <td>travel British Airways Sweden Los Angeles vi...</td>\n",
       "      <td>-0.7902</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "      <td>Food was lousy Who ever is planning the Asian...</td>\n",
       "      <td>[(Food, n), (lousy, n), (ever, r), (planning, ...</td>\n",
       "      <td>Food lousy ever plan Asian Hindu Vegetarian ...</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "      <td>Had the worst experience The flight from Lond...</td>\n",
       "      <td>[(worst, a), (experience, n), (flight, n), (Lo...</td>\n",
       "      <td>bad experience flight London Toronto get del...</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "      <td>The ground staff were not helpful Felt like a...</td>\n",
       "      <td>[(ground, n), (staff, n), (helpful, a), (Felt,...</td>\n",
       "      <td>ground staff helpful Felt like want rush us ...</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0   Regarding the aircraft and seat: The business...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2    Food was lousy. Who ever is planning the Asi...   \n",
       "3   Had the worst experience. The flight from Lon...   \n",
       "4    The ground staff were not helpful. Felt like...   \n",
       "\n",
       "                                     Cleaned Reviews  \\\n",
       "0   Regarding the aircraft and seat The business ...   \n",
       "1   I travelled with British Airways from Sweden ...   \n",
       "2   Food was lousy Who ever is planning the Asian...   \n",
       "3   Had the worst experience The flight from Lond...   \n",
       "4   The ground staff were not helpful Felt like a...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(Regarding, v), (aircraft, n), (seat, v), (bu...   \n",
       "1  [(travelled, v), (British, a), (Airways, n), (...   \n",
       "2  [(Food, n), (lousy, n), (ever, r), (planning, ...   \n",
       "3  [(worst, a), (experience, n), (flight, n), (Lo...   \n",
       "4  [(ground, n), (staff, n), (helpful, a), (Felt,...   \n",
       "\n",
       "                                               Lemma  Sentiment  Analysis  \n",
       "0    Regarding aircraft seat business class seat ...     0.8676  Positive  \n",
       "1    travel British Airways Sweden Los Angeles vi...    -0.7902  Negative  \n",
       "2    Food lousy ever plan Asian Hindu Vegetarian ...    -0.5574  Negative  \n",
       "3    bad experience flight London Toronto get del...     0.1546   Neutral  \n",
       "4    ground staff helpful Felt like want rush us ...     0.6124  Positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# function to calculate vader sentiment\n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "\n",
    "df['Sentiment'] = df['Lemma'].apply(vadersentimentanalysis)\n",
    "\n",
    "# function to analyse\n",
    "def vader_analysis(compound):\n",
    "    if compound >= 0.5:\n",
    "        return 'Positive'\n",
    "    elif compound < 0 :\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "df['Analysis'] = df['Sentiment'].apply(vader_analysis)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4bf1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    524\n",
       "Negative    370\n",
       "Neutral     106\n",
       "Name: Analysis, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_counts = df['Analysis'].value_counts()\n",
    "vader_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510cb64",
   "metadata": {},
   "source": [
    "# Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f19dfd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x26b21e25eb0>,\n",
       "  <matplotlib.patches.Wedge at 0x26b21e394f0>,\n",
       "  <matplotlib.patches.Wedge at 0x26b21e39c10>],\n",
       " [Text(-0.08285944828829273, 1.096874793141569, 'Positive'),\n",
       "  Text(-0.2802478556160989, -1.0637016214251902, 'Negative'),\n",
       "  Text(1.2758351325693755, -0.44129889474332934, 'Neutral')],\n",
       " [Text(-0.04519606270270512, 0.598295341713583, '52.4%'),\n",
       "  Text(-0.15286246669969028, -0.58020088441374, '37.0%'),\n",
       "  Text(0.8033036019881252, -0.2778548596532074, '10.6%')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Reviews Analysis\")\n",
    "plt.pie(vader_counts.values, labels = vader_counts.index, explode = (0, 0, 0.25), autopct='%1.1f%%', shadow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed760b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e670a05",
   "metadata": {},
   "source": [
    "# TASK 1 OVER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740e926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
